{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7967dc-ff13-4dd1-ae9b-79b4fb815d43",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904f28b2-531d-4c57-a934-d257b8b2b348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            instruction  \\\n",
      "0  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "1  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "2  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "3  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "4  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "\n",
      "                                               input  \\\n",
      "0  宠物出现以下症状：lethargy (嗜睡)、lameness (跛行)、neurologi...   \n",
      "1  宠物出现以下症状：lameness (跛行)、neurological disorders ...   \n",
      "2  宠物出现以下症状：lethargy (嗜睡)、fever (发烧)、tick fever (...   \n",
      "3  宠物出现以下症状：lameness (跛行)、nasal discharge (鼻腔分泌物)...   \n",
      "4  宠物出现以下症状：weight loss (体重减轻)、heart complication...   \n",
      "\n",
      "                                              output  \n",
      "0  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "1  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "2  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "3  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "4  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23999 entries, 0 to 23998\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   instruction  23999 non-null  object\n",
      " 1   input        23999 non-null  object\n",
      " 2   output       23999 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 562.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据集\n",
    "data_path = \"lora_finetune.xlsx\"\n",
    "df = pd.read_excel(data_path)\n",
    "\n",
    "# 查看数据前几行\n",
    "print(df.head())\n",
    "\n",
    "# 查看数据基本信息\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e50d88-896f-426e-851e-5ff0d968f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instruction    0\n",
      "input          0\n",
      "output         0\n",
      "dtype: int64\n",
      "                            instruction  \\\n",
      "0  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "1  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "2  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "3  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "4  您好，我是一个专业的宠物健康顾问AI，可以通过分析症状来诊断宠物的疾病。   \n",
      "\n",
      "                                               input  \\\n",
      "0  宠物出现以下症状：lethargy (嗜睡)、lameness (跛行)、neurologi...   \n",
      "1  宠物出现以下症状：lameness (跛行)、neurological disorders ...   \n",
      "2  宠物出现以下症状：lethargy (嗜睡)、fever (发烧)、tick fever (...   \n",
      "3  宠物出现以下症状：lameness (跛行)、nasal discharge (鼻腔分泌物)...   \n",
      "4  宠物出现以下症状：weight loss (体重减轻)、heart complication...   \n",
      "\n",
      "                                              output  \n",
      "0  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "1  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "2  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "3  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n",
      "4  根据提供的症状，宠物可能患有Tick fever (蜱热)，请及时就医，具体诊断和治疗方案请...  \n"
     ]
    }
   ],
   "source": [
    "# 检查是否有缺失值\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 填充缺失值（如果有）\n",
    "df.fillna({\"instruction\": \"\", \"input\": \"\", \"output\": \"\"}, inplace=True)\n",
    "\n",
    "# 标准化文本格式\n",
    "df[\"instruction\"] = df[\"instruction\"].str.strip()\n",
    "df[\"input\"] = df[\"input\"].str.strip()\n",
    "df[\"output\"] = df[\"output\"].str.strip()\n",
    "\n",
    "# 再次检查数据\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac3adf4-b9a8-4fed-a9ba-e4b46a4dbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# 保存为 JSON 文件（用于后续模型训练）\n",
    "train_df.to_json(\"train_data.json\", orient=\"records\", lines=True)\n",
    "val_df.to_json(\"val_data.json\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25f4c2a-0026-46c7-b829-ef37725c348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b0bd45c-0dc4-406f-aa0d-eae5f9c6765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee157d163fb44784862fc1ae79863756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69557f8-5263-4623-8808-1ffcff0bd2eb",
   "metadata": {},
   "source": [
    "## 数据集tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5f153e-56d0-4fc3-8bc1-68596e99db67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b24179245bf4eac82bdf464da5ec502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1159023807044a82b83b727b35ea07cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d32446e3e114d37bc7df49bd21bc683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fbe9e2fac94671b83a6fc312510a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af16a27c37940a1bdc96afeeb334835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# 加载 JSON 数据集\n",
    "train_dataset = load_dataset(\"json\", data_files=\"train_data.json\", split=\"train\")\n",
    "val_dataset = load_dataset(\"json\", data_files=\"val_data.json\", split=\"train\")\n",
    "\n",
    "# 加载预训练模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "\n",
    "# 配置 LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # LoRA 的秩（rank），控制低秩矩阵的大小\n",
    "    lora_alpha=32,  # 缩放因子\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # 根据模型架构选择目标模块\n",
    "    lora_dropout=0.1,  # Dropout 比例\n",
    "    bias=\"none\",  # 是否调整偏置\n",
    "    task_type=\"CAUSAL_LM\"  # 任务类型\n",
    ")\n",
    "\n",
    "# 将模型包装为 LoRA 模型\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # 确保 inputs 和 outputs 是字符串列表\n",
    "    inputs = [str(instr) + \" \" + str(inp) for instr, inp in zip(examples[\"instruction\"], examples[\"input\"])]\n",
    "    outputs = [str(out) for out in examples[\"output\"]]\n",
    "    \n",
    "    # 对输入和输出进行编码\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(outputs, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    # 将标签添加到模型输入中\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# 对数据集进行 Tokenization\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 使用 DataCollator 进行动态填充\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512,  # 确保与 tokenize_function 中的 max_length 一致\n",
    "    label_pad_token_id=-100  # 忽略填充部分的损失计算\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b48eb85-819e-42eb-a4a5-278fe5295e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1545/1839693703.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2500/2500 33:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.583500</td>\n",
       "      <td>2.317346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.358600</td>\n",
       "      <td>1.318141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>0.906990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>0.717508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>0.556764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.483720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.439482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.418765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.408550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.391500</td>\n",
       "      <td>0.401827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=1.485931826019287, metrics={'train_runtime': 2014.862, 'train_samples_per_second': 4.963, 'train_steps_per_second': 1.241, 'total_flos': 8.52976730112e+16, 'train_loss': 1.485931826019287, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_qwen-3b\",  # 输出目录\n",
    "    eval_strategy=\"epoch\",           # 每个 epoch 进行一次评估\n",
    "    learning_rate=1e-5,              # 学习率\n",
    "    per_device_train_batch_size=1,  # 训练时每个设备的批量大小\n",
    "    per_device_eval_batch_size=1,   # 评估时每个设备的批量大小\n",
    "    num_train_epochs=10,             # 训练轮数\n",
    "    weight_decay=0.01,              # 权重衰减\n",
    "    save_strategy=\"steps\",          # 按步数保存\n",
    "    save_steps=500,                 # 每 500 步保存一次\n",
    "    logging_dir=\"./logs\",           # 日志目录\n",
    "    logging_steps=50,               # 每 50 步记录一次日志\n",
    "    fp16=True,                      # 使用混合精度训练（需要支持 GPU）\n",
    "    gradient_accumulation_steps=4,  # 增加梯度累积步数\n",
    ")\n",
    "\n",
    "# 初始化 Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train.select(range(1000)),  # 只使用前 1000 条数据\n",
    "    eval_dataset=tokenized_val.select(range(500)),      # 只使用前 500 条数据\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 开始训练\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35ad8c7-dd1e-475a-b1d7-7dea8e27d86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./results_qwen-3b/tokenizer_config.json',\n",
       " './results_qwen-3b/special_tokens_map.json',\n",
       " './results_qwen-3b/vocab.json',\n",
       " './results_qwen-3b/merges.txt',\n",
       " './results_qwen-3b/added_tokens.json',\n",
       " './results_qwen-3b/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 保存微调后的模型\n",
    "model.save_pretrained(\"./results_qwen-3b\")\n",
    "tokenizer.save_pretrained(\"./results_qwen-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5aec7b-e244-4783-a4b7-e5ebe8948f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子 1: 最近的观察表明，动物类型:Dog 品种:Labrador 年龄:4岁 性别:Male 体重:25.0公斤, 症状1:Fever 症状2:Lethargy 症状3:Appetite Loss 症状4:Vomiting 持续时间:3 days\n",
      "健康建议: 输入：\n",
      "\n",
      "根据您提供的信息，您提到的4岁成年雄性拉布拉多犬出现了持续3天的发热、嗜睡、食欲不振和呕吐的症状。这些症状可能由多种原因引起，包括感染性疾病（如病毒、细菌或寄生虫感染）、消化系统疾病（如胃肠道疾病或食物中毒）或代谢性疾病等。\n",
      "\n",
      "可能的原因：\n",
      "1. 感染性疾病\n",
      "2. 消化系统疾病\n",
      "3. 代谢性疾病\n",
      "4. 其他疾病（例如肿瘤）\n",
      "\n",
      "处理步骤:\n",
      "1. 尽快带宠物去看兽医，进行详细检查和诊断。\n",
      "2. 根据兽医的建议进行治疗，可能需要进行血液检查、尿液检查、影像学检查（如X光或超声波）等。\n",
      "3. 遵医嘱给宠物喂食易消化的食物，如煮熟的鸡肉和米饭。\n",
      "4. 保持宠物的环境清洁卫生，避免接触其他患病的宠物。\n",
      "5. 观察宠物的症状是否有改善或恶化，及时与兽医沟通。\n",
      "\n",
      "注意事项：\n",
      "1、不要自行给宠物使用抗生素或其他药物，除非兽医明确指示。\n",
      "2、密切观察宠物的体温、精神状态、排\n",
      "\n",
      "句子 2: 食欲减退:Yes 呕吐:Yes 腹泻:No 咳嗽:No 呼吸困难:No 关节疼痛:No 皮肤病变:No 鼻分泌物:No 眼分泌物:No\n",
      "健康建议: 根据您提供的症状，宠物可能患有消化系统疾病。可能的原因包括：\n",
      "\n",
      "1. 消化不良\n",
      "2. 肠炎\n",
      "3. 胃炎\n",
      "4. 食物过敏\n",
      "5. 细菌感染\n",
      "6. 病毒感染\n",
      "7. 寄生虫感染\n",
      "8. 药物过敏\n",
      "\n",
      "处理步骤：\n",
      "1. 尽量让宠物禁食12-24小时，以减轻胃肠道负担。\n",
      "2. 给宠物提供清淡易消化的食物，如煮熟的鸡肉和白米饭。\n",
      "3. 观察宠物的排便情况，如果出现血便或粘液便，应立即就医。\n",
      "4. 如果宠物出现脱水症状，如尿量减少、口干舌燥、眼窝凹陷等，需要及时补充水分。\n",
      "5. 如果症状持续或加重，应尽快带宠物就医。\n",
      "\n",
      "注意事项：\n",
      "- 在禁食期间，不要给宠物喂食任何食物或饮料，包括水。\n",
      "- 在宠物恢复进食后，应逐渐恢复正常饮食，避免突然改变饮食习惯。\n",
      "- 保持宠物的生活环境清洁卫生，定期清洁宠物的食盆和水盆。\n",
      "- 注意观察宠物的其他症状，\n",
      "\n",
      "句子 3: 我家的狗目前体温:39.5°C 心率:120，持续发热嗜睡\n",
      "健康建议: 的\n",
      "\n",
      "可能的原因：\n",
      "1. 感染\n",
      "2. 疼痛\n",
      "3. 肿瘤\n",
      "4. 神经系统疾病\n",
      "5. 药物反应\n",
      "\n",
      "处理步骤:\n",
      "1. 尽快带宠物去看兽医。\n",
      "2. 遵循兽医的建议进行治疗。\n",
      "3. 保持宠物的清洁和舒适。\n",
      "4. 观察宠物的症状是否有改善或恶化。\n",
      "\n",
      "注意事项:\n",
      "- 不要自行给宠物使用任何药物。\n",
      "- 避免让宠物过度活动。\n",
      "- 注意宠物的饮食和饮水。 根据您提供的症状和可能的原因，您的狗目前可能患有感染、疼痛、肿瘤、神经系统疾病或药物反应。为了确保宠物的健康和安全，建议尽快带宠物去兽医处进行详细检查和治疗。在等待就医的过程中，请遵循以下处理步骤：\n",
      "\n",
      "1. **尽快就医**：立即带宠物前往兽医诊所或联系兽医进行远程咨询，以便获得专业的诊断和治疗建议。\n",
      "\n",
      "2. **遵循兽医建议**：根据兽医的具体指导进行治疗，包括但不限于药物使用、饮食调整等。\n",
      "\n",
      "3. **保持宠物舒适**：确保宠物在一个安静、温暖且舒适的环境中休息。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def generate_health_advice(instruction, input_text):\n",
    "    # 将指令和输入拼接成完整输入\n",
    "    full_input = f\"{instruction} 输入：{input_text}\"\n",
    "    \n",
    "    # 对输入进行编码\n",
    "    inputs = tokenizer(\n",
    "        full_input,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    # 确保输入张量在正确的设备上\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 使用 num_beams > 1 并移除 early_stopping\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=256,  # 增加最大生成长度\n",
    "        num_beams=4,         # 使用束搜索\n",
    "        do_sample=True,      # 启用采样\n",
    "        temperature=0.7,     # 控制随机性\n",
    "        top_p=0.9,           # 核采样\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # 解码生成的 token\n",
    "    advice = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # 提取生成的实际建议部分\n",
    "    advice = advice.replace(full_input, \"\").strip()\n",
    "    return advice\n",
    "\n",
    "# 示例输入\n",
    "example_instruction = (\n",
    "    \"您是经过培训的宠物个性化医疗保健代理，可以根据宠物的症状和体征，提供详细的诊断建议和护理指南。\"\n",
    "    \"请分析以下输入中的症状，列出可能的原因，并给出具体的处理步骤和注意事项。\"\n",
    ")\n",
    "example_input = (\n",
    "    \"最近的观察表明，动物类型:Dog 品种:Labrador 年龄:4岁 性别:Male 体重:25.0公斤, \"\n",
    "    \"症状1:Fever 症状2:Lethargy 症状3:Appetite Loss 症状4:Vomiting 持续时间:3 days。\"\n",
    "    \"食欲减退:Yes 呕吐:Yes 腹泻:No 咳嗽:No 呼吸困难:No 关节疼痛:No 皮肤病变:No 鼻分泌物:No 眼分泌物:No。\"\n",
    "    \"我家的狗目前体温:39.5°C 心率:120，持续发热嗜睡\"\n",
    ")\n",
    "\n",
    "# 分割输入文本为句子\n",
    "sentences = [s.strip() for s in re.split(r'[。！？]', example_input) if s.strip()]\n",
    "\n",
    "# 逐句生成健康建议\n",
    "results = []\n",
    "for sentence in sentences:\n",
    "    advice = generate_health_advice(example_instruction, sentence)\n",
    "    results.append((sentence, advice))\n",
    "\n",
    "# 输出结果\n",
    "for i, (sentence, advice) in enumerate(results):\n",
    "    print(f\"句子 {i+1}: {sentence}\")\n",
    "    print(f\"健康建议: {advice}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
